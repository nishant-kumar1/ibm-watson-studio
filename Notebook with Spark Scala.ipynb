{
    "cells": [
        {
            "metadata": {
                "collapsed": true
            },
            "cell_type": "markdown",
            "source": "Sample notebook using spark and scala"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\n// @hidden_cell\nimport com.ibm.ibmos2spark.CloudObjectStorage\nvar configurationName = \"os_22316821dc2847a788b1760edc7b1786_configs\"\ndef getCredentials(): scala.collection.mutable.HashMap[String, String] = {\n    return scala.collection.mutable.HashMap[String, String] (\n    \"endPoint\"->\"https://s3.eu-geo.objectstorage.service.networklayer.com\",\n    \"apiKey\"->\"U0F78Txs5xf17RJ7cyfI3cd8khIPbm7UqgNUOPjsE2l9\",\n    \"serviceId\"->\"iam-ServiceId-90c8806f-d8ac-41b7-aecd-1ec9d9551cff\",\n    \"iamServiceEndpoint\" -> \"https://iam.cloud.ibm.com/oidc/token\")\n}\n\nvar cos = new CloudObjectStorage(sc, getCredentials(), configurationName, \"bluemix_cos\")\n\nimport org.apache.spark.sql.SparkSession\nval spark = SparkSession.\n    builder().\n    getOrCreate()\nval dfData1 = spark.\n    read.format(\"org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\").\n    option(\"header\", \"true\").\n    option(\"inferSchema\", \"true\").\n    load(cos.url(\"samplejupyternotebook-donotdelete-pr-uywwnvgk9rab87\", \"datasets_19_420_Iris.csv\"))\ndfData1.show(5)\n",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+---+-------------+------------+-------------+------------+-----------+\n| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n+---+-------------+------------+-------------+------------+-----------+\n|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n+---+-------------+------------+-------------+------------+-----------+\nonly showing top 5 rows\n\n",
                    "name": "stdout"
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "configurationName = os_22316821dc2847a788b1760edc7b1786_configs\ncos = com.ibm.ibmos2spark.CloudObjectStorage@b3e2f716\nspark = org.apache.spark.sql.SparkSession@d3c7dcce\ndfData1 = [Id: int, SepalLengthCm: double ... 4 more fields]\n"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "getCredentials: ()scala.collection.mutable.HashMap[String,String]\n"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 1,
                    "data": {
                        "text/plain": "[Id: int, SepalLengthCm: double ... 4 more fields]"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "scala",
            "display_name": "Scala 2.11 with Spark",
            "language": "scala"
        },
        "language_info": {
            "mimetype": "text/x-scala",
            "name": "scala",
            "pygments_lexer": "scala",
            "version": "2.11.12",
            "file_extension": ".scala",
            "codemirror_mode": "text/x-scala"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}